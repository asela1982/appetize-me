{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../ScrapeData/csv_recipes/recipe_df1.csv')\n",
    "df2 = pd.read_csv('../ScrapeData/csv_recipes/recipe_df2.csv')\n",
    "df3 = pd.read_csv('../ScrapeData/csv_recipes/recipe_df3.csv')\n",
    "df4 = pd.read_csv('../ScrapeData/csv_recipes/recipe_df4.csv')\n",
    "df5 = pd.read_csv('../ScrapeData/csv_recipes/recipe_df5.csv')\n",
    "df6 = pd.read_csv('../ScrapeData/csv_recipes/recipe_df6.csv')\n",
    "df7 = pd.read_csv('../ScrapeData/csv_recipes/recipe_df7.csv')\n",
    "df8 = pd.read_csv('../ScrapeData/csv_recipes/recipe_df8.csv')\n",
    "\n",
    "## concat the dataframes\n",
    "df = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8])\n",
    "\n",
    "# Drop Unnamed and id columns before we dropping rows with empty cells.\n",
    "df.drop('Unnamed: 0',axis=1, inplace=True)\n",
    "\n",
    "\n",
    "clean_df = df.dropna(axis=0, how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepositions = [\"A\", \"An\", \"a\", \"about\", \"above\", \"above\", \"across\", \"additional\",\"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"plus\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thickly\", \"thin\", \"thinly\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common measurement words and hard-coded words.\n",
    "measurement_words = ['pound',\n",
    " 'cubes',\"Fresh\",\n",
    "  'cups',\n",
    "  'cut',\n",
    " 'kilogram',\n",
    " 'ounce','-ounce','ounces',\n",
    " 'gram','large',\n",
    " 'cup','ground',\n",
    " 'spoon','trimmed',\n",
    " 'quart',\n",
    " 'teaspoon','teaspoons',\n",
    " 'smidgen','chopped',\n",
    " 'drop','medium', 'small',\n",
    " 'gallon',\n",
    " 'dash',\n",
    " 'handful',\n",
    " 'scoop',\n",
    " 'bowl',\n",
    " 'inch',\n",
    " '-inch','freshly', 'bunch',\n",
    " 'pinch','finely',\n",
    " 'liter',\n",
    " 'milliliter',\n",
    " 'tablespoon', 'tablespoons',\n",
    " 'fluid',\n",
    " 'bottle','stems', 'removed',\n",
    " 'tad','Instant',\n",
    " 'pint', 'Tbsp', 'tsp','lb', '-oz', 'oz','sliced','diced','Pot', 'pot','-','-pound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "for word in prepositions:\n",
    "    stopWords.append(word)\n",
    "for word in measurement_words:\n",
    "    stopWords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/tom/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:25: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/tom/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "clean_df[\"ingredients_list\"] = \"\"\n",
    "for idx, row in clean_df.iterrows():\n",
    "    ingredients_items = ast.literal_eval(row[\"ingredients\"])\n",
    "    \n",
    "# ingredients = all_clean_recipes['ingredients'].iloc[0]\n",
    "#     ingredient_items = ast.literal_eval(ingredients)\n",
    "\n",
    "    ingredients = []\n",
    "    pattern = \"([^\\d\\\\.\\\\,\\\\\\;\\\\*\\\\]\\\\[\\\\%\\\\½\\\\<\\\\>\\\\:\\\\°\\\\?\\\\�\\\\}\\\\{\\)\\(\\\"\\/\\s]+)\"\n",
    "    for ingredient in ingredients_items:\n",
    "        p = re.compile(pattern)\n",
    "        result = p.findall(ingredient) \n",
    "        ingredients.append(result)\n",
    "\n",
    "    single_ingr = sum(ingredients, [])\n",
    "    recipe_ingr = list(set(single_ingr))\n",
    "\n",
    "\n",
    "    filtered_ingr = []\n",
    "    for item in recipe_ingr:\n",
    "        if item not in stopWords:\n",
    "            filtered_ingr.append(item)\n",
    "    recipes_df = clean_df.set_value(idx,\"ingredients_list\",filtered_ingr) \n",
    "\n",
    "recipes_df[\"ingredients_string\"] = recipes_df[\"ingredients_list\"].map(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bestrating</th>\n",
       "      <th>id</th>\n",
       "      <th>imagesrc</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>makeitagainscore</th>\n",
       "      <th>preparation</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients_list</th>\n",
       "      <th>ingredients_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://assets.epicurious.com/photos/560dd82af...</td>\n",
       "      <td>['2 tablespoons extra-virgin olive oil', '1/2 ...</td>\n",
       "      <td>75%</td>\n",
       "      <td>1. In a large pot over medium heat, warm the o...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>['Italian', 'Bean', 'Cheese', 'Pasta', 'Tomato...</td>\n",
       "      <td>Pasta with Lentil Bolognese</td>\n",
       "      <td>[carrot, cheese, tomato, onion, black, grated,...</td>\n",
       "      <td>carrot,cheese,tomato,onion,black,grated,cloves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://assets.epicurious.com/photos/59a42793e...</td>\n",
       "      <td>['3/4 cup plus 2 tablespoons all purpose flour...</td>\n",
       "      <td>84%</td>\n",
       "      <td>Whisk flour and cocoa in medium bowl. Beat but...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>['American', 'Milk/Cream', 'Mixer', 'Chocolate...</td>\n",
       "      <td>Milky Way Tart</td>\n",
       "      <td>[yolk, cocoa, heavy, purpose, whipping, flour,...</td>\n",
       "      <td>yolk,cocoa,heavy,purpose,whipping,flour,prefer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bestrating   id                                           imagesrc  \\\n",
       "0         4.0  0.0  https://assets.epicurious.com/photos/560dd82af...   \n",
       "1         4.0  1.0  https://assets.epicurious.com/photos/59a42793e...   \n",
       "\n",
       "                                         ingredients makeitagainscore  \\\n",
       "0  ['2 tablespoons extra-virgin olive oil', '1/2 ...              75%   \n",
       "1  ['3/4 cup plus 2 tablespoons all purpose flour...              84%   \n",
       "\n",
       "                                         preparation  rating  reviews  \\\n",
       "0  1. In a large pot over medium heat, warm the o...     3.0     17.0   \n",
       "1  Whisk flour and cocoa in medium bowl. Beat but...     3.5     35.0   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Italian', 'Bean', 'Cheese', 'Pasta', 'Tomato...   \n",
       "1  ['American', 'Milk/Cream', 'Mixer', 'Chocolate...   \n",
       "\n",
       "                          title  \\\n",
       "0  Pasta with Lentil Bolognese    \n",
       "1               Milky Way Tart    \n",
       "\n",
       "                                    ingredients_list  \\\n",
       "0  [carrot, cheese, tomato, onion, black, grated,...   \n",
       "1  [yolk, cocoa, heavy, purpose, whipping, flour,...   \n",
       "\n",
       "                                  ingredients_string  \n",
       "0  carrot,cheese,tomato,onion,black,grated,cloves...  \n",
       "1  yolk,cocoa,heavy,purpose,whipping,flour,prefer...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carrot,cheese,tomato,onion,black,grated,cloves,salt,roughly,drained,dried,garlic,rigatoni,tomatoes,peeled,extra-virgin,reserved,cans,green,sea,optional,plum,shaped,French,cavatappi,taste,minced,oil,ziti,shaved,lentils,olive,pasta,basil,Coarse,pepper,celery,stalk,Pecorino,juice,kosher,paste\n"
     ]
    }
   ],
   "source": [
    "print(recipes_df[\"ingredients_string\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
